# Model architecture and optimization parameters

in_size: 500
hidden_size: 256

model_type: MLP

get_first: 5 # not used for LSTM

loss: CE
opt: Adam
lr: 0.0002

# Training dataset parameters

training:
  bs: 1024

# Augmentation params

augmentation:
  shift:
    - -10
    - 10
  add:
    - -0.1
    - 0.1
  random_noise: 0.1
  scale:
    - 0.9
    - 1.2
  dropping_aug:
    - 0.05
    - 0.1

# Data sources and formula converters

data:
  converter: vector
  converter_settings:
    normalizer: sum
  is_classifier: true

  representations: /home/boiko/mra/training_data.tsv.gz
